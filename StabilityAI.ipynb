{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucEl7lKUizY-",
        "outputId": "80c7724f-8826-4a22-c532-910acb58aa32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgit8moikvZ",
        "outputId": "6900f3f0-117d-43d3-acc8-c799ba5ed8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "access_token = \"Enter your hugging face token here\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablecode-instruct-alpha-3b\", token = access_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"stabilityai/stablecode-instruct-alpha-3b\",\n",
        "  trust_remote_code=True,\n",
        "  torch_dtype=\"auto\",\n",
        "  token = access_token\n",
        ")\n",
        "model.cuda()\n",
        "inputs = tokenizer(\"###Instruction\\nGenerate a python function to find number of CPU cores###Response\\n\", return_tensors=\"pt\").to(\"cuda\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del inputs[\"token_type_ids\"]\n",
        "tokens = model.generate(\n",
        "**inputs,\n",
        "max_new_tokens=20,\n",
        "temperature=0.2,\n",
        "do_sample=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJRCoai9GD0f",
        "outputId": "ce275794-9836-46ca-b000-601648c123b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokens[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnBy1gshF_oN",
        "outputId": "bda81a1c-e579-4ead-81e5-938e9a302a54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Instruction\n",
            "Generate a python function to find number of CPU cores###Response\n",
            "def get_cpu_count():\n",
            "    \"\"\"\n",
            "    Returns the number of CPU cores\n",
            "    \"\"\"\n",
            "    import\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "  del inputs[\"token_type_ids\"]\n",
        "  tokens = model.generate(\n",
        "  **inputs,\n",
        "  max_new_tokens=20,\n",
        "  temperature=0.2,\n",
        "  do_sample=True,\n",
        ")\n",
        "  return tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QfPiDf1Rsz5_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_input(prompt):\n",
        "  user_input = input(prompt)\n",
        "  return str(user_input)"
      ],
      "metadata": {
        "id": "lAoXjx5GlKD7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_for_help(code_string):\n",
        "  need_help = get_user_input(\"Do you need help with this code? (yes/no): \")\n",
        "  flag = 0\n",
        "  if need_help.lower() == \"yes\":\n",
        "    result = generate_code(code_string)\n",
        "    print(\"\\nNew code:\\n\")\n",
        "    print(result)\n",
        "\n",
        "    accept = get_user_input(\"\\nDo you accept this code? (yes/no): \")\n",
        "    if accept.lower() == \"yes\":\n",
        "        code_string = result\n",
        "        flag = 1\n",
        "  return code_string, flag"
      ],
      "metadata": {
        "id": "O9cIhLWzckC1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Welcome to Code Enhancer!\")\n",
        "    code_sequence = \"\"  # To store the accumulated code sequence\n",
        "\n",
        "    while True:\n",
        "        # Take input from the user\n",
        "        user_input = get_user_input(\"Enter your Python code (or 'exit' to quit): \")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Exiting the Code Enhancer.\")\n",
        "            break\n",
        "\n",
        "        code_string = str(user_input)\n",
        "        code_sequence += code_string\n",
        "\n",
        "        while True:\n",
        "            code_string, flag = ask_for_help(code_sequence)\n",
        "            continue_input = get_user_input(\"\\nDo you want more help? (yes/no): \")\n",
        "            if continue_input.lower() == \"no\":\n",
        "                print(\"Exiting the Code Enhancer.\")\n",
        "                break\n",
        "        if flag == 1:\n",
        "          code_sequence = code_string  # Append the current code to the sequence\n",
        "\n",
        "\n",
        "    print(\"Final Code sequence:\")\n",
        "    print(code_sequence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "GzC-wwTMbbNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fed0aa-f7d4-4315-b093-e461bd802d80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to Code Enhancer!\n",
            "Enter your Python code (or 'exit' to quit): def calculator(a,b,operator):\n",
            "Do you need help with this code? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New code:\n",
            "\n",
            "def calculator(a,b,operator):\n",
            "    if operator == \"+\":\n",
            "        return a + b\n",
            "    elif operator == \"-\":\n",
            "        return a\n",
            "\n",
            "Do you accept this code? (yes/no): yes\n",
            "\n",
            "Do you want more help? (yes/no): no\n",
            "Exiting the Code Enhancer.\n",
            "Enter your Python code (or 'exit' to quit): -b\n",
            "Do you need help with this code? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New code:\n",
            "\n",
            "def calculator(a,b,operator):\n",
            "    if operator == \"+\":\n",
            "        return a + b\n",
            "    elif operator == \"-\":\n",
            "        return a-b\n",
            "    elif operator == \"*\":\n",
            "        return a*b\n",
            "    elif operator == \"/\":\n",
            "        return a\n",
            "\n",
            "Do you accept this code? (yes/no): yes\n",
            "\n",
            "Do you want more help? (yes/no): no\n",
            "Exiting the Code Enhancer.\n",
            "Enter your Python code (or 'exit' to quit): /b\n",
            "Do you need help with this code? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New code:\n",
            "\n",
            "def calculator(a,b,operator):\n",
            "    if operator == \"+\":\n",
            "        return a + b\n",
            "    elif operator == \"-\":\n",
            "        return a-b\n",
            "    elif operator == \"*\":\n",
            "        return a*b\n",
            "    elif operator == \"/\":\n",
            "        return a/b\n",
            "\n",
            "Do you accept this code? (yes/no): yes\n",
            "\n",
            "Do you want more help? (yes/no): no\n",
            "Exiting the Code Enhancer.\n",
            "Enter your Python code (or 'exit' to quit): exit\n",
            "Exiting the Code Enhancer.\n",
            "Final Code sequence:\n",
            "def calculator(a,b,operator):\n",
            "    if operator == \"+\":\n",
            "        return a + b\n",
            "    elif operator == \"-\":\n",
            "        return a-b\n",
            "    elif operator == \"*\":\n",
            "        return a*b\n",
            "    elif operator == \"/\":\n",
            "        return a/b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "id": "DGeEUXGqccwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}